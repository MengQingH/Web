# 负载均衡
负载均衡是一种计算机技术，用来在多个计算机（集群）、网络连接或其他资源中分配负载，达到最大化资源使用、最大化吞吐率、最小化响应时间、避免高过载的目的。负载均衡可以使用硬件或软件来完成。

**网络中的负载均衡**：是高可用网络基础架构的关键**组件**，通常用于将工作负载分布到多个服务器来提高网站、应用、数据库或其他服务的性能和可靠性。实现：
* 使用硬件实现，如F5、Array等负载均衡器。
* 使用软件进行负载均衡：
    * 阿里云服务器负载均衡SBL。
    * Nginx+Keepalived。
    * LVS(Linux Virtual Server)、haproxy等。

如果一个服务器没有负载均衡，那么如果这个服务器出现宕机，或者是很多请求同时访问服务器超过了其能处理的极限，就会出现加载速度过慢或者是根本无法访问的情况。

而如果在后端引入一个负载均衡器和至少一个额外的服务器，就可以缓解这个故障。通常情况下所有的后端服务器会保证提供相同的内容，以便用户无论在哪个服务器响应，都能收到一致的请求。
<br><img src=img/负载均衡.png><br>

## 负载均衡处理的请求类型
负载均衡器的管理员能主要为下面四种类型的请求设置转发规则：
* HTTP
* HTTPS
* TCP
* UDP

## 负载均衡选择转发的后端服务器
负载均衡器一般根据两个因素来决定要将请求转发到哪个服务器。首先，确保选择的服务器能够对请求做出响应，然后根据预先配置的规则从健康服务器池中进行选择。

只有能够正常响应的服务器能进入健康服务器池，为了监视后台服务器的运行状态，服务器运行状态检查服务会定期的尝试用转发规则定义的协议和端口去连接后端服务器，如果服务器无法通过检查，就会从池中剔除，保证请求不会转发到该服务器，直到再次通过检查为止。

## 负载均衡算法
负载均衡算法决定了后端的哪些健康服务器会被选中。几个常用的算法：
* Round Robin（轮循）：按顺序逐个选择服务器直到结尾，然后循环。
* Least Connections（最小连接）：优先选择连接数最小的服务器，在普遍会话较长的情况下推荐使用。
* Source：根据请求源的IP的散列选择要转发的服务器，这种方式一定程度上可以保证特定的用户能连接到相同的服务器。

## 负载均衡器的单点故障
在上图中的负载均衡解决方法中，如果只使用一个负载均衡器，那么单点故障就会发生在负载均衡器上，如果负载均衡器出现故障，那么也无法处理请求。此时可以使用两个负载均衡器，把第二个连接到第一个上，从而形成一个集群。